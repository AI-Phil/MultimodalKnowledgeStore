{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a virtual environment or similar (this was built with Python 3.10, but 3.11 should work too), and install `requirements.txt`:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "2. Setup Google Cloud Application Default Credentials (see [this doc](https://cloud.google.com/docs/authentication/provide-credentials-adc)).\n",
    "3. Copy the `.env.template` file and set keys and other information as indicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `.env` file into the Python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize VertexAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import vertexai\n",
    "vertexai.init(\n",
    "    project=os.environ.get(\"GOOGLE_PROJECT_NAME\"),\n",
    "    location=os.environ.get(\"GOOGLE_LOCATION\",'us-east1'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LangChain VertexAI components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "llmModel = VertexAI(model_name=os.environ.get('GOOGLE_LLM','gemini-1.5-flash'))\n",
    "chatModel = ChatVertexAI(model=os.environ.get('GOOGLE_LLM','gemini-1.5-flash'))\n",
    "embedModel = VertexAIEmbeddings(model_name=os.environ.get('GOOGLE_EMBED_MODEL','multimodalembedding')) \n",
    "genModel = GenerativeModel(model_name=os.environ.get('GOOGLE_LLM','gemini-1.5-flash'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Cassio (Astra DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio\n",
    "cassio.init(auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And establish the graph store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragstack_langchain.graph_store import CassandraGraphStore     \n",
    "\n",
    "SITE_PREFIX=\"travel_docs\"\n",
    "graph_store = CassandraGraphStore(\n",
    "    embedModel,\n",
    "    node_table=f\"{SITE_PREFIX}_nodes\",\n",
    "    edge_table=f\"{SITE_PREFIX}_edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Load LangChain `Document`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example `Tourbook.pdf` is fairly complex in structure, both digitally and visually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variety of parsing tools such as Unstructured and Adobe ExtractAPI were attempted on `Tourbook.pdf` file, attempting with both file structure and OCR techniques, to no avail. The Vertex LLM was able to parse (with a fairly generic prompt), but unfortunately exited early as it determined it was repeating existing content and cited the URL of this!\n",
    "\n",
    "In this notebook we are trying to demonstrate multi-modal embedding and retrieval, so the information was manually parsed, and put into the file `Tourbook.json`. This contains the first 24 pages minus the cover page, the table of contents, and a map on page 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from ragstack_knowledge_store.link_tag import BidirLinkTag\n",
    "import json\n",
    "\n",
    "with open('Tourbook.json', 'r', encoding='utf-8') as file:\n",
    "    text_data = json.load(file)\n",
    "\n",
    "text_documents = []\n",
    "h1_dict = {}\n",
    "\n",
    "for i, entry in enumerate(text_data):\n",
    "    # Capture the H1 header for each page for future reference\n",
    "    h1 = entry['metadata'].get('h1')\n",
    "    if h1:\n",
    "        h1_dict[entry['metadata']['page_number']] = h1\n",
    "\n",
    "    mime_type = entry['metadata'].get('mime_type','text/plain').split('/')\n",
    "    entry['metadata']['mime_type'] = mime_type[0]\n",
    "    if len(mime_type) > 1:\n",
    "        entry['metadata']['mime_subtype'] = '/'.join(mime_type[1:])\n",
    "\n",
    "    # Identify all header levels in the metadata and sort them\n",
    "    headers = sorted([key for key in entry['metadata'] if key.startswith('h')], key=lambda x: int(x[1:]))\n",
    "    if headers:\n",
    "        # Lowest level header is the last in the sorted list\n",
    "        lowest_header = headers[-1]\n",
    "        header_content = entry['metadata'][lowest_header]\n",
    "        link_header = BidirLinkTag(kind=lowest_header, tag=header_content)\n",
    "        entry['metadata']['link_tags'] = [link_header]\n",
    "    \n",
    "    doc = Document(page_content=entry['page_content'], metadata=entry['metadata'])\n",
    "    text_documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `metadata.link_tags` list; here we are linking to and from the H1 header level, which corresponds to the section. In this way, any information in a section will be linked to other information in the section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For images, we will use `PyMuPDF` to extract images from the document, `base64` encode the image, and create a `Document` referencing the appropriate H1 heading for the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import base64\n",
    "\n",
    "doc = pymupdf.open('Tourbook.pdf')\n",
    "image_documents = []\n",
    "\n",
    "# page_index starts from 0, so these are actual pages 3, 5-23, but are numbered 1 and 3-21. \n",
    "pages_to_process = [2] + list(range(4, 23))  \n",
    "\n",
    "for page_index in pages_to_process:\n",
    "    page = doc[page_index]\n",
    "    image_list = page.get_images()\n",
    "    adjusted_page_number = page_index - 1\n",
    "\n",
    "    # Iterate over the images on the page\n",
    "    for image_index, img in enumerate(image_list, start=1):\n",
    "        xref = img[0]\n",
    "        pix = pymupdf.Pixmap(doc, xref) \n",
    "        if pix.n - pix.alpha > 3:\n",
    "            pix = pymupdf.Pixmap(pymupdf.csRGB, pix)\n",
    "\n",
    "        base64_image = base64.b64encode(pix.tobytes(output=\"png\")).decode('utf-8')\n",
    "\n",
    "        if adjusted_page_number % 2 == 0:  # If it's even\n",
    "            page_spread = f\"{adjusted_page_number}-{adjusted_page_number+1}\"\n",
    "        else:  # If it's odd\n",
    "            page_spread = f\"{adjusted_page_number-1}-{adjusted_page_number}\"\n",
    "\n",
    "        h1 = h1_dict[adjusted_page_number]\n",
    "        link_h1 = BidirLinkTag(kind=\"h1\", tag=h1)\n",
    "        doc_metadata = {\n",
    "            \"mime_type\": \"image\",\n",
    "            \"mime_subtype\": \"png\",\n",
    "            \"mime_encoding\": \"base64\",\n",
    "            \"page_number\": adjusted_page_number, \n",
    "            \"page_spread\": page_spread, \n",
    "            \"image_index\": image_index,\n",
    "            \"h1\": h1, \n",
    "            \"link_tags\" : [ link_h1 ]\n",
    "\n",
    "        }\n",
    "        # Now in theory, langchain_google_vertex.embeddings.embed_image() calls ImageBytesLoader.load_bytes\n",
    "        # which can take a base64 string, but that wasn't working...but this URI trick does work!\n",
    "        image_doc = Document(page_content=f\"data:image/png;base64,{base64_image}\", metadata=doc_metadata)\n",
    "        image_documents.append(image_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Knowledge Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving batch\n",
      "saving batch\n",
      "saving batch\n",
      "saving batch\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "#for doc in text_documents + image_documents:\n",
    "for doc in text_documents:\n",
    "    docs.append(doc)\n",
    "\n",
    "    if len(docs) >= 50:\n",
    "        print(\"saving batch\")\n",
    "        graph_store.add_documents(docs)\n",
    "        docs.clear()\n",
    "\n",
    "if docs:\n",
    "    print(\"saving batch\")\n",
    "    graph_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful travel agent bot. \n",
    "You should provide answers to the travellers questions in a manner that encourages them to travel, without sounding American. \n",
    "Include specific details of things to see and do, so that you appear knowledgeable about the destination. Give a detailed itinerary.\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted = \"\\n\\n\".join(f\"From {doc.metadata['content_id']}: {doc.page_content}\" for doc in docs)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Helper method to render markdown in responses to a chain.\n",
    "def run_and_render(chain, question):\n",
    "    result = chain.invoke(question)\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ServiceUnavailable: 503 Getting metadata from plugin failed with error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ServiceUnavailable: 503 Connection reset.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Ah, the Golden Triangle - a true gem of India!  It's a journey that will transport you through history, culture, and vibrant colours.  \n",
       "\n",
       "You'll find yourself in Delhi, the bustling heart of India, where you can wander through the ancient bazaars of Chandni Chowk, explore the majestic Red Fort, and delve into the spiritual heart of the city at the Lotus Temple. \n",
       "\n",
       "Then, Agra beckons, home to the timeless Taj Mahal, a testament to eternal love and architectural brilliance.  Be sure to witness the sunrise over this ethereal masterpiece - it's a moment you'll never forget! \n",
       "\n",
       "Finally, you'll arrive in Jaipur, the 'Pink City', where palaces shimmer in the desert sun and the Hawa Mahal, the 'Palace of Winds', stands as a testament to the city's rich history.  Don't miss the opportunity to explore the vibrant markets and witness the local artisans at work.  \n",
       "\n",
       "This is just a taste of what awaits you in the Golden Triangle.  Let your senses be captivated by the vibrant colours, the enticing aromas, and the warmth of the Indian people.  \n",
       "\n",
       "Now, would you like to explore a few ways to enhance your Golden Triangle adventure? Perhaps extend your journey with a river cruise on the Brahmaputra or add a few days in the mystical region of Rajasthan?  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Depth 0 doesn't traverses edges and is equivalent to vector similarity only.\n",
    "vector_retriever = graph_store.as_retriever(search_kwargs={\"depth\": 0})\n",
    "\n",
    "vector_rag_chain = (\n",
    "    {\"context\": vector_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "QUESTION=\"What can I do in the golden triangle?\"\n",
    "run_and_render(vector_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Golden Triangle is a classic journey through India, taking you to three incredible cities: Delhi, Agra, and Jaipur. \n",
       "\n",
       "In Delhi, you'll be swept away by the energy of the bustling capital. Explore the magnificent Red Fort and the Jama Masjid, one of India's largest mosques.  You can also visit the impressive Qutub Minar, a UNESCO World Heritage Site, or lose yourself in the colourful streets of Chandni Chowk, a bustling bazaar overflowing with spices, fabrics, and everything imaginable.\n",
       "\n",
       "Next, journey to Agra, home to the iconic Taj Mahal, a monument to love built by Mughal Emperor Shah Jahan for his beloved wife Mumtaz Mahal.  You'll be mesmerized by its beauty, built entirely from white marble, and adorned with intricate details. Agra Fort, another UNESCO World Heritage Site, offers breathtaking views and showcases the architectural mastery of the Mughal era.\n",
       "\n",
       "Finally, head to Jaipur, the vibrant Pink City, known for its magnificent forts, palaces, and bustling bazaars.  Explore the majestic Amber Fort, atop a hill overlooking the city, and learn about the colourful history of the region. Visit the City Palace, a stunning complex of courtyards and gardens, or wander through the Hawa Mahal, the Palace of Winds, with its intricate latticework windows.  Jaipur is a feast for the senses, with its vibrant bazaars, offering everything from textiles and jewellery to spices and handicrafts.\n",
       "\n",
       "The Golden Triangle offers a glimpse into the rich history, vibrant culture, and breathtaking beauty of India.  What are you waiting for? Start planning your journey today! \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Depth 1 does vector similarity and then traverses 1 level of edges.\n",
    "graph_retriever = graph_store.as_retriever(search_kwargs={\"depth\": 1})\n",
    "\n",
    "graph_rag_chain = (\n",
    "    {\"context\": graph_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "run_and_render(graph_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ah, the Golden Triangle!  A journey through the heart of India, brimming with rich history and vibrant culture.  \n",
       "\n",
       "The classic route weaves through Delhi, Agra, and Jaipur, each city a treasure trove of architectural marvels, bustling bazaars, and delicious cuisine. \n",
       "\n",
       "In Delhi, immerse yourself in the grandeur of the Red Fort and the Jama Masjid, the largest mosque in India. Explore the bustling Chandni Chowk market and savour the fragrant street food.\n",
       "\n",
       "Agra is synonymous with the Taj Mahal, a breathtaking monument to love, a testament to Mughal artistry.  Don't miss the Agra Fort, a UNESCO World Heritage Site, and indulge in the local delicacies of 'Petha' and 'Dal Moth'.\n",
       "\n",
       "Jaipur, the Pink City, is a kaleidoscope of colour and charm.  Admire the Hawa Mahal, a palace with 953 windows, and wander through the City Palace, a masterpiece of Rajput architecture.  Explore the vibrant bazaars and witness the artistry of the local artisans.\n",
       "\n",
       "Consider adding an extension to your journey to enhance your experience.  Perhaps a visit to the birthplace of Lord Buddha in Lumbini, Nepal, or a journey into the breathtaking Himalayas? \n",
       "\n",
       "Let me know if you have other questions, and I'll be happy to share more about this exciting journey! \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mmr_graph_retriever = graph_store.as_retriever(\n",
    "    search_type = \"mmr_traversal\",\n",
    "    search_kwargs = {\n",
    "        \"k\": 4,\n",
    "        \"fetch_k\": 10,\n",
    "        \"depth\": 2,\n",
    "        # \"score_threshold\": 0.2,\n",
    "    },\n",
    ")\n",
    "\n",
    "mmr_graph_rag_chain = (\n",
    "    {\"context\": mmr_graph_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "run_and_render(mmr_graph_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You can go on a camel ride in many places around the world, including:\n",
       "\n",
       "* **India:** The Thar Desert in Rajasthan is a popular destination for camel safaris. \n",
       "* **Morocco:** The Sahara Desert in Morocco offers stunning camel treks through the dunes.\n",
       "* **Egypt:** The Western Desert of Egypt is home to the White Desert National Park, where you can ride camels and explore unique rock formations.\n",
       "* **UAE:** The Liwa Oasis in the United Arab Emirates offers camel rides through the Rub' al Khali desert.\n",
       "* **Australia:** The Outback of Australia has many camel farms and tour operators offering camel rides.\n",
       "* **Peru:** The Atacama Desert in Peru is another place where you can enjoy a camel trek. \n",
       "\n",
       "Before booking a camel ride, it is essential to do your research and choose a reputable operator that prioritizes animal welfare. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "image_message = {\n",
    "    \"type\": \"image_url\",\n",
    "    \"image_url\": {\"url\":\"camel-riding.jpg\"},\n",
    "}\n",
    "\n",
    "text_message = {\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"Where can I do this?\",\n",
    "}\n",
    "message = HumanMessage(content=[text_message, image_message])\n",
    "\n",
    "output = chatModel.invoke([message])\n",
    "display(Markdown(output.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ServiceUnavailable: 503 Connection reset.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "\n",
    "def describe_image(llm: BaseChatModel, image_url: str, instruct: str) -> str:\n",
    "    \"\"\"Describe the contents of an image.\"\"\"\n",
    "    system_message = SystemMessage(content=\"\"\"\n",
    "        You are a tool that converts images to text.     \n",
    "    \"\"\")\n",
    "\n",
    "    image_message = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": instruct or \"Describe the contents of this image.\"},\n",
    "    {\"type\": \"image_url\",\"image_url\": {\"url\":image_url}}\n",
    "    ])\n",
    "    \n",
    "    output = llm.invoke([system_message, image_message])\n",
    "    return output.content\n",
    "    \n",
    "image_description = describe_image(chatModel,\"camel-riding.jpg\",\"Describe the image as completely as possible in 50-80 words, in a manner that is suitable for searching travel brochures.\")\n",
    "IMAGE_QUESTION=f\"Image: {image_description}\\n Where can I do this?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ah, a camel ride through the desert! That sounds like an excellent adventure.  You can experience the thrill of riding a camel across the golden sands of Jaisalmer in Rajasthan, India. Imagine yourself riding through the dunes, the sun setting over the horizon, casting long shadows on the sand. It's truly a breathtaking sight!  Just picture yourself being guided by experienced locals who can share stories of the desert, its history, and its people. This is a truly unforgettable cultural experience you won't want to miss. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_and_render(graph_rag_chain, IMAGE_QUESTION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
